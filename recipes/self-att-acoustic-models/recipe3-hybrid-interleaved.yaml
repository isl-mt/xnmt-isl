# Attentional ASR with self-attentional acoustic model, variant 3:
# Hybrid self-attentional encoder with interleaved LSTM layers and no positional encodings.
#
recipe3-hybrid-interleaved: !Experiment

  exp_global: !ExpGlobal

    # global model settings
    dropout: 0.2
    default_layer_dim: 512

    # holds the TEDLIUM data with speaker-normalized 40-dim Mel filterbank features
    placeholders:
      DATA_DIR: /project/data-audio/tedlium-multi/parallel/en/tedlium-40

  model: !DefaultTranslator

    src_embedder: !NoopEmbedder # acoustic encoders have no word embeddings
      emb_dim: 40

    encoder: !ModularSeqTransducer # defines the self-attentional encoder / acoustic model
      modules:
      - !TransformerSeqTransducer # 2 downsampling self-attentional layers
        layers: 2
        input_dim: 40
        hidden_dim: 512
        downsample_factor: 2
        ff_hidden_dim: 512
        max_len: 1500
        ff_lstm: True
      - !TransformerSeqTransducer # LSTM layer at the top
        layers: 1
        input_dim: 512
        hidden_dim: 512
        downsample_factor: 1
        ff_hidden_dim: 512
        ff_lstm: True

    # remaining components are as in a standard NMT model
    attender: !MlpAttender
      hidden_dim: 128
    trg_embedder: !SimpleWordEmbedder
      emb_dim: 64
      word_dropout: 0.1
      fix_norm: 1
    decoder: !MlpSoftmaxDecoder
      layers: 1
      lstm_dim: 512
      input_feeding: True
      bridge: !NoBridge {}
      label_smoothing: 0.1
    src_reader: !ContVecReader
      transpose: true
      feat_from: 0
      feat_to: 40
    trg_reader: !PlainTextReader
      vocab: !Vocab
        vocab_file: '{DATA_DIR}/train/src.char.vocab.manual' # character output vocabulary

  train: !SimpleTrainingRegimen
    src_file: '{DATA_DIR}/train/src.contvec.npz'
    trg_file: '{DATA_DIR}/train/src.char'
    max_src_len: &max_src_len 1500
    max_trg_len: 350

    run_for_epochs: 500
    batcher: !WordSrcBatcher
      avg_batch_size: 18
      pad_src_to_multiple: 4 # character output vocabulary
      src_pad_token: ~
    trainer: !AdamTrainer
      alpha: 0.0003
    lr_decay: 0.5
    lr_decay_times: 3
    patience: 5
    initial_patience: 10
    dev_every: 0
    restart_trainer: True

    dev_tasks:
      - !AccuracyEvalTask
        eval_metrics: wer,cer
        src_file: &dev_src '{DATA_DIR}/dev/src.contvec.npz'
        ref_file: '{DATA_DIR}/dev/src.txt'
        hyp_file: '{EXP_DIR}/models/{EXP}.dev_hyp'
        inference: !SimpleInference
          post_process: join-char
          search_strategy: !BeamSearch
            beam_size: 20
            max_len: 500
            len_norm: !PolynomialNormalization
              apply_during_search: true
              m: 1.5
      - !LossEvalTask
        src_file: *dev_src
        ref_file: '{DATA_DIR}/dev/src.char'
  evaluate:
    - !AccuracyEvalTask
      eval_metrics: wer,cer
      src_file: &test_src '{DATA_DIR}test/src.contvec.npz'
      ref_file: '{DATA_DIR}/test/src.txt'
      hyp_file: '{EXP_DIR}/models/{EXP}.test_hyp'
      inference: !SimpleInference
        post_process: join-char
        search_strategy: !BeamSearch
          beam_size: 20
          max_len: 500
          len_norm: !PolynomialNormalization
            apply_during_search: true
            m: 1.5
    - !LossEvalTask
      src_file: *test_src
      ref_file: '{DATA_DIR}/test/src.char'
